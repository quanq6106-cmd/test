{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaH100","dataSources":[{"sourceId":118448,"databundleVersionId":14559231,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":3424966,"sourceType":"datasetVersion","datasetId":2035671},{"sourceId":3818163,"sourceType":"datasetVersion","datasetId":2274483},{"sourceId":4501486,"sourceType":"datasetVersion","datasetId":2631784},{"sourceId":5258124,"sourceType":"datasetVersion","datasetId":3059801},{"sourceId":9971715,"sourceType":"datasetVersion","datasetId":6134857},{"sourceId":11087772,"sourceType":"datasetVersion","datasetId":4576291},{"sourceId":11497644,"sourceType":"datasetVersion","datasetId":7207743},{"sourceId":11564740,"sourceType":"datasetVersion","datasetId":7251054},{"sourceId":11739593,"sourceType":"datasetVersion","datasetId":5773627},{"sourceId":363168,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":301540,"modelId":322000}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# CELL 2 (REPLACE) — install xong KHÔNG import transformers ở đây (để tránh cache về disk trước)\n!pip -q install -U --no-cache-dir \\\n  \"transformers>=4.51.0\" \\\n  \"accelerate>=0.30.0\" \\\n  \"datasets>=2.19.0\" \\\n  \"peft>=0.11.0\" \\\n  \"trl>=0.9.6\" \\\n  \"bitsandbytes>=0.43.1\" \\\n  \"huggingface_hub>=0.23.0\" \\\n  \"tokenizers>=0.21.0\" \\\n  \"safetensors>=0.4.3\" \\\n  \"sentencepiece\" \\\n  \"jsonschema>=4.22.0\" \\\n  \"rapidfuzz>=3.9.0\" \\\n  \"openpyxl>=3.1.5\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T04:46:29.420625Z","iopub.execute_input":"2026-01-21T04:46:29.421215Z","iopub.status.idle":"2026-01-21T04:46:51.461106Z","shell.execute_reply.started":"2026-01-21T04:46:29.421196Z","shell.execute_reply":"2026-01-21T04:46:51.460569Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m522.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.2/515.2 kB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.0/557.0 kB\u001b[0m \u001b[31m528.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/532.5 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m152.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m200.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m535.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m482.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m151.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nray 2.52.1 requires click!=8.3.*,>=7.0, but you have click 8.3.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# CELL 1 (REPLACE) — RAM mode phải chạy TRƯỚC MỌI import transformers/tokenizers/peft\nimport os\nfrom pathlib import Path\n\n!df -h /dev/shm\n\nRAM_BASE = Path(\"/dev/shm/kaggle_ram\")\nRAM_BASE.mkdir(parents=True, exist_ok=True)\n\nHF_HOME = RAM_BASE / \"hf\"\nHF_HOME.mkdir(parents=True, exist_ok=True)\n\nos.environ[\"HF_HOME\"] = str(HF_HOME)\nos.environ[\"HF_HUB_CACHE\"] = str(HF_HOME / \"hub\")\nos.environ[\"HF_DATASETS_CACHE\"] = str(HF_HOME / \"datasets\")\nos.environ[\"TRANSFORMERS_CACHE\"] = str(HF_HOME / \"transformers\")\nos.environ[\"TORCH_HOME\"] = str(RAM_BASE / \"torch\")\nos.environ[\"XDG_CACHE_HOME\"] = str(RAM_BASE / \".cache\")\n\n# outputs/logs cũng đẩy vào RAM\nWORKDIR = RAM_BASE / \"working\"\nDATA_DIR = WORKDIR / \"data\"\nTEACH_CACHE_DIR = WORKDIR / \"teacher_outputs\"\nWORKDIR.mkdir(parents=True, exist_ok=True)\nDATA_DIR.mkdir(parents=True, exist_ok=True)\nTEACH_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"HF_HOME =\", os.environ[\"HF_HOME\"])\nprint(\"HF_HUB_CACHE =\", os.environ[\"HF_HUB_CACHE\"])\nprint(\"WORKDIR =\", WORKDIR)\nprint(\"DATA_DIR =\", DATA_DIR)\nprint(\"TEACH_CACHE_DIR =\", TEACH_CACHE_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T04:46:51.462157Z","iopub.execute_input":"2026-01-21T04:46:51.462336Z","iopub.status.idle":"2026-01-21T04:46:51.581978Z","shell.execute_reply.started":"2026-01-21T04:46:51.462305Z","shell.execute_reply":"2026-01-21T04:46:51.581487Z"}},"outputs":[{"name":"stdout","text":"Filesystem      Size  Used Avail Use% Mounted on\nshm             114G     0  114G   0% /dev/shm\nHF_HOME = /dev/shm/kaggle_ram/hf\nHF_HUB_CACHE = /dev/shm/kaggle_ram/hf/hub\nWORKDIR = /dev/shm/kaggle_ram/working\nDATA_DIR = /dev/shm/kaggle_ram/working/data\nTEACH_CACHE_DIR = /dev/shm/kaggle_ram/working/teacher_outputs\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# CELL 3 (REPLACE) — setup PATHS/QWEN32B_PATH nhưng KHÔNG reset WORKDIR/DATA_DIR về /kaggle/working nữa\nimport os, re, json, time, math, random\nfrom glob import glob\n\n# WORKDIR/DATA_DIR đã được set từ CELL 1 (RAM). Không ghi đè lại.\nDATA_DIR.mkdir(parents=True, exist_ok=True)\n\ndef find_qwen32b_path():\n    candidates = []\n    for p in glob(\"/kaggle/input/**\", recursive=True):\n        if os.path.isdir(p):\n            low = p.lower()\n            if \"qwen\" in low and (\"32b\" in low or \"32-b\" in low):\n                if os.path.exists(os.path.join(p, \"config.json\")):\n                    candidates.append(p)\n    candidates = sorted(candidates, key=lambda x: len(x))\n    return candidates[0] if candidates else None\n\nQWEN32B_PATH = find_qwen32b_path()\nprint(\"QWEN32B_PATH =\", QWEN32B_PATH)\n\nTEACHERS = {\n    \"open_finance_8b\": \"DragonLLM/Llama-Open-Finance-8B\",\n    \"finance_llama3_8b\": \"instruction-pretrain/finance-Llama3-8B\",\n    \"fingpt_lora_llama3_8b\": \"FinGPT/fingpt-mt_llama3-8b_lora\",\n}\nFINGPT_BASE = \"meta-llama/Meta-Llama-3-8B\"\n\nPATHS = {\n    \"vn_mcocr\": \"/kaggle/input/vietnamese-receipts-mc-ocr-2021\",\n    \"invoice_ocr\": \"/kaggle/input/invoice-ocr\",\n    \"hi_quality_invoice\": \"/kaggle/input/high-quality-invoice-images-for-ocr\",\n    \"gl_xlsx\": \"/kaggle/input/generalledger/Data file for students.xlsx\",\n    \"transactions_csv\": \"/kaggle/input/financial-transactions-dataset/financial_transactions.csv\",\n    \"forecast_csv\": \"/kaggle/input/financial-forecasting-data/simulated_financial_forecasting_data.csv\",\n    \"data_retriever_csv\": \"/kaggle/input/data-retreiver/Data_ret.csv\",\n}\nprint(\"DATA PATHS OK\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T04:46:51.582765Z","iopub.execute_input":"2026-01-21T04:46:51.582925Z","iopub.status.idle":"2026-01-21T04:52:10.895783Z","shell.execute_reply.started":"2026-01-21T04:46:51.582907Z","shell.execute_reply":"2026-01-21T04:52:10.895353Z"}},"outputs":[{"name":"stdout","text":"QWEN32B_PATH = /kaggle/input/qwen-3/transformers/32b/1\nDATA PATHS OK\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from jsonschema import validate\nfrom jsonschema.exceptions import ValidationError\n\n# ===== Schemas =====\nRECEIPT_SCHEMA = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"vendor_name\": {\"type\": [\"string\", \"null\"]},\n        \"address\": {\"type\": [\"string\", \"null\"]},\n        \"date\": {\"type\": [\"string\", \"null\"]},            # YYYY-MM-DD preferred\n        \"total_amount\": {\"type\": [\"number\", \"null\"]},\n        \"currency\": {\"type\": [\"string\", \"null\"]},        # \"VND\"\n        \"confidence\": {\"type\": \"number\"},\n        \"flags\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n    },\n    \"required\": [\"vendor_name\",\"address\",\"date\",\"total_amount\",\"currency\",\"confidence\",\"flags\"]\n}\n\nINVOICE_SCHEMA = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"vendor_name\": {\"type\": [\"string\", \"null\"]},\n        \"invoice_no\": {\"type\": [\"string\", \"null\"]},\n        \"date\": {\"type\": [\"string\", \"null\"]},\n        \"subtotal\": {\"type\": [\"number\", \"null\"]},\n        \"tax\": {\"type\": [\"number\", \"null\"]},\n        \"total\": {\"type\": [\"number\", \"null\"]},\n        \"currency\": {\"type\": [\"string\", \"null\"]},\n        \"confidence\": {\"type\": \"number\"},\n        \"flags\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n    },\n    \"required\": [\"vendor_name\",\"invoice_no\",\"date\",\"subtotal\",\"tax\",\"total\",\"currency\",\"confidence\",\"flags\"]\n}\n\nJOURNAL_SCHEMA = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"entries\": {\n            \"type\": \"array\",\n            \"items\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"account\": {\"type\": \"string\"},\n                    \"debit\": {\"type\": \"number\"},\n                    \"credit\": {\"type\": \"number\"},\n                    \"memo\": {\"type\": [\"string\",\"null\"]}\n                },\n                \"required\": [\"account\",\"debit\",\"credit\",\"memo\"]\n            }\n        },\n        \"confidence\": {\"type\": \"number\"},\n        \"flags\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n    },\n    \"required\": [\"entries\",\"confidence\",\"flags\"]\n}\n\nTASK2SCHEMA = {\n    \"receipt_extract_text\": RECEIPT_SCHEMA,\n    \"invoice_extract_text\": INVOICE_SCHEMA,\n    \"journal_from_structured_txn\": JOURNAL_SCHEMA,\n}\n\ndef schema_pass(task: str, obj: dict) -> bool:\n    try:\n        validate(instance=obj, schema=TASK2SCHEMA[task])\n        return True\n    except ValidationError:\n        return False\n    except Exception:\n        return False\n\n# ===== JSON extract / repair =====\ndef extract_json_from_text(text: str):\n    if text is None:\n        return None\n    # pick first {...} block\n    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n    if not m:\n        return None\n    s = m.group(0)\n    try:\n        return json.loads(s)\n    except Exception:\n        return None\n\ndef json_repair_minimal(text: str):\n    \"\"\"\n    deterministic repair for common LLM issues:\n    - trailing commas\n    - single quotes -> double quotes (simple cases)\n    \"\"\"\n    if text is None:\n        return None\n    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n    if not m:\n        return None\n    s = m.group(0).strip()\n\n    s = re.sub(r\",\\s*}\", \"}\", s)\n    s = re.sub(r\",\\s*]\", \"]\", s)\n    # naive quote fix (only if it looks like JSON)\n    if \"'\" in s and '\"' not in s:\n        s = s.replace(\"'\", '\"')\n\n    try:\n        return json.loads(s)\n    except Exception:\n        return None\n\n# ===== Prompt builder =====\ndef build_prompt(task: str, input_data):\n    if task == \"receipt_extract_text\":\n        return f\"\"\"\nExtract receipt key fields from Vietnamese text.\nReturn ONLY valid JSON with fields:\nvendor_name,address,date,total_amount,currency,confidence,flags\n\nReceipt Text:\n{input_data}\n\"\"\".strip()\n\n    if task == \"invoice_extract_text\":\n        return f\"\"\"\nExtract invoice fields from text.\nReturn ONLY valid JSON with fields:\nvendor_name,invoice_no,date,subtotal,tax,total,currency,confidence,flags\n\nInvoice Text:\n{input_data}\n\"\"\".strip()\n\n    if task == \"journal_from_structured_txn\":\n        return f\"\"\"\nYou are an ERP accountant.\nGiven a structured transaction JSON, propose journal entries.\nReturn ONLY valid JSON with fields:\n- entries: array of objects (account, debit, credit, memo)\n- confidence\n- flags\n\nTransaction:\n{json.dumps(input_data, ensure_ascii=False)}\n\"\"\".strip()\n\n    raise ValueError(\"Unknown task\")\n\nprint(\"Schemas + prompt builder ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T04:52:10.896818Z","iopub.execute_input":"2026-01-21T04:52:10.896969Z","iopub.status.idle":"2026-01-21T04:52:11.805826Z","shell.execute_reply.started":"2026-01-21T04:52:10.896955Z","shell.execute_reply":"2026-01-21T04:52:11.805337Z"}},"outputs":[{"name":"stdout","text":"Schemas + prompt builder ready.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\ndef infer_col(df, candidates):\n    cols = {c.lower(): c for c in df.columns}\n    for cand in candidates:\n        if cand.lower() in cols:\n            return cols[cand.lower()]\n    # fuzzy contains\n    for c in df.columns:\n        low = c.lower()\n        for cand in candidates:\n            if cand.lower() in low:\n                return c\n    return None\n\ndef load_vn_mcocr_cases(limit=300):\n    root = PATHS[\"vn_mcocr\"]\n    cases = []\n\n    # Prefer CSV with gold labels if present\n    csv_candidates = [\n        os.path.join(root, \"mcocr_train_df.csv\"),\n        os.path.join(root, \"mcocr_val_sample_df.csv\"),\n        os.path.join(root, \"results.csv\"),\n    ]\n    for p in csv_candidates:\n        if os.path.exists(p):\n            df = pd.read_csv(p)\n\n            text_col = infer_col(df, [\"text\", \"ocr_text\", \"raw_text\", \"content\", \"transcription\"])\n            if text_col is None:\n                # fallback pick longest string col\n                str_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n                if str_cols:\n                    text_col = max(str_cols, key=lambda c: df[c].astype(str).str.len().mean())\n\n            seller_col = infer_col(df, [\"seller\", \"vendor\", \"vendor_name\", \"merchant\", \"store\", \"shop\"])\n            addr_col   = infer_col(df, [\"address\", \"seller_address\", \"vendor_address\"])\n            date_col   = infer_col(df, [\"timestamp\", \"date\", \"datetime\", \"time\"])\n            total_col  = infer_col(df, [\"total_cost\", \"total\", \"amount\", \"total_amount\", \"sum\"])\n\n            for i, row in df.head(limit).iterrows():\n                raw_text = str(row[text_col]) if text_col else \"\"\n\n                gold = None\n                if seller_col or addr_col or date_col or total_col:\n                    def safe_float(x):\n                        try:\n                            if pd.isna(x): \n                                return None\n                            s = str(x)\n                            s = re.sub(r\"[^\\d\\.\\-]\", \"\", s)\n                            return float(s) if s else None\n                        except:\n                            return None\n\n                    gold = {\n                        \"vendor_name\": str(row[seller_col]) if seller_col and pd.notna(row[seller_col]) else None,\n                        \"address\": str(row[addr_col]) if addr_col and pd.notna(row[addr_col]) else None,\n                        \"date\": str(row[date_col]) if date_col and pd.notna(row[date_col]) else None,\n                        \"total_amount\": safe_float(row[total_col]) if total_col else None,\n                        \"currency\": \"VND\",\n                        \"confidence\": 0.0,\n                        \"flags\": []\n                    }\n\n                cases.append({\n                    \"id\": f\"vn_mcocr_{i}\",\n                    \"task\": \"receipt_extract_text\",\n                    \"input\": raw_text,\n                    \"gold\": gold,\n                    \"meta\": {\"source\": os.path.basename(p)}\n                })\n            return cases\n\n    # fallback txt (OCR lines)\n    txt_candidates = [\n        os.path.join(root, \"text_recognition_train_data.txt\"),\n        os.path.join(root, \"text_recognition_val_data.txt\"),\n    ]\n    for p in txt_candidates:\n        if os.path.exists(p):\n            with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n                for idx, line in enumerate(f):\n                    if idx >= limit:\n                        break\n                    parts = line.strip().split(\"\\t\")\n                    raw_text = parts[-1] if parts else \"\"\n                    cases.append({\n                        \"id\": f\"vn_mcocr_txt_{idx}\",\n                        \"task\": \"receipt_extract_text\",\n                        \"input\": raw_text,\n                        \"gold\": None,\n                        \"meta\": {\"source\": os.path.basename(p)}\n                    })\n            return cases\n\n    return []\n\ndef load_gl_cases(limit=200):\n    xlsx_path = PATHS[\"gl_xlsx\"]\n    if not os.path.exists(xlsx_path):\n        return []\n    xls = pd.ExcelFile(xlsx_path)\n    # take first sheet by default\n    df = pd.read_excel(xlsx_path, sheet_name=xls.sheet_names[0])\n\n    cases = []\n    for i, row in df.head(limit).iterrows():\n        txn = row.to_dict()\n        cases.append({\n            \"id\": f\"gl_{i}\",\n            \"task\": \"journal_from_structured_txn\",\n            \"input\": txn,\n            \"gold\": None,\n            \"meta\": {\"sheet\": xls.sheet_names[0]}\n        })\n    return cases\n\ndef load_invoice_ocr_cases(limit=200):\n    \"\"\"\n    Robust loader:\n    - If JSON/CSV annotations exist -> use their text fields\n    - Otherwise use image paths (text-only LLM can't read images, but still valid for KD if you later OCR)\n    \"\"\"\n    root = PATHS[\"invoice_ocr\"]\n    if not os.path.exists(root):\n        return []\n\n    ann_files = []\n    for ext in [\"*.json\",\"*.csv\"]:\n        ann_files += glob(os.path.join(root, \"**\", ext), recursive=True)\n\n    cases = []\n    if ann_files:\n        # take first annotation file found\n        p = ann_files[0]\n        if p.endswith(\".csv\"):\n            df = pd.read_csv(p)\n            text_col = infer_col(df, [\"text\",\"ocr\",\"raw\",\"content\"])\n            for i, row in df.head(limit).iterrows():\n                raw_text = str(row[text_col]) if text_col else \"\"\n                cases.append({\n                    \"id\": f\"invoice_ocr_csv_{i}\",\n                    \"task\": \"invoice_extract_text\",\n                    \"input\": raw_text,\n                    \"gold\": None,\n                    \"meta\": {\"ann\": os.path.basename(p)}\n                })\n        else:\n            with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n                js = json.load(f)\n            # try to find list items with \"text\"\n            items = []\n            if isinstance(js, list):\n                items = js\n            elif isinstance(js, dict):\n                # common keys\n                for k in [\"data\",\"items\",\"annotations\",\"samples\"]:\n                    if k in js and isinstance(js[k], list):\n                        items = js[k]\n                        break\n\n            for i, it in enumerate(items[:limit]):\n                raw_text = it.get(\"text\") or it.get(\"ocr_text\") or it.get(\"content\") or \"\"\n                cases.append({\n                    \"id\": f\"invoice_ocr_json_{i}\",\n                    \"task\": \"invoice_extract_text\",\n                    \"input\": str(raw_text),\n                    \"gold\": None,\n                    \"meta\": {\"ann\": os.path.basename(p)}\n                })\n\n        return cases\n\n    # fallback: use image paths (for later OCR pipeline)\n    imgs = glob(os.path.join(root, \"**\", \"*.png\"), recursive=True) + glob(os.path.join(root, \"**\", \"*.jpg\"), recursive=True)\n    for i, ip in enumerate(imgs[:limit]):\n        cases.append({\n            \"id\": f\"invoice_ocr_img_{i}\",\n            \"task\": \"invoice_extract_text\",\n            \"input\": f\"[IMAGE_PATH]{ip}\",\n            \"gold\": None,\n            \"meta\": {\"img\": os.path.basename(ip)}\n        })\n    return cases\n\nprint(\"Loaders ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T04:52:11.806468Z","iopub.execute_input":"2026-01-21T04:52:11.806610Z","iopub.status.idle":"2026-01-21T04:52:12.093815Z","shell.execute_reply.started":"2026-01-21T04:52:11.806595Z","shell.execute_reply":"2026-01-21T04:52:12.093364Z"}},"outputs":[{"name":"stdout","text":"Loaders ready.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime, date\n\ndef _json_default(o):\n    if isinstance(o, (pd.Timestamp, datetime, date)):\n        return o.isoformat()\n    if isinstance(o, (np.integer,)):\n        return int(o)\n    if isinstance(o, (np.floating,)):\n        return float(o)\n    if isinstance(o, (np.ndarray,)):\n        return o.tolist()\n    return str(o)\n\ndef write_jsonl(path, rows):\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        for r in rows:\n            f.write(json.dumps(r, ensure_ascii=False, default=_json_default) + \"\\n\")\n\n\neval_cases = []\neval_cases += load_vn_mcocr_cases(limit=300)\neval_cases += load_invoice_ocr_cases(limit=200)\neval_cases += load_gl_cases(limit=150)\n\nprint(\"Total eval cases:\", len(eval_cases))\neval_path = str(DATA_DIR / \"eval_cases.jsonl\")\nwrite_jsonl(eval_path, eval_cases)\nprint(\"Saved:\", eval_path)\n\n# KD training uses the same pool (you can enlarge later)\nkd_pool = eval_cases.copy()\nrandom.shuffle(kd_pool)\nkd_pool = kd_pool[:500]  # keep KD small for iteration speed\nkd_pool_path = str(DATA_DIR / \"kd_pool.jsonl\")\nwrite_jsonl(kd_pool_path, kd_pool)\nprint(\"Saved KD pool:\", kd_pool_path, \"| size:\", len(kd_pool))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T04:52:12.094481Z","iopub.execute_input":"2026-01-21T04:52:12.094692Z","iopub.status.idle":"2026-01-21T04:52:13.986192Z","shell.execute_reply.started":"2026-01-21T04:52:12.094676Z","shell.execute_reply":"2026-01-21T04:52:13.985750Z"}},"outputs":[{"name":"stdout","text":"Total eval cases: 450\nSaved: /dev/shm/kaggle_ram/working/data/eval_cases.jsonl\nSaved KD pool: /dev/shm/kaggle_ram/working/data/kd_pool.jsonl | size: 450\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# CELL 4 (REPLACE) — model utils: add load_fingpt + force cache_dir=RAM\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import PeftModel\n\ntorch.backends.cuda.matmul.allow_tf32 = True\ntorch.backends.cudnn.allow_tf32 = True\n\nbnb4 = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n)\n\nHF_CACHE_DIR = os.environ[\"HF_HUB_CACHE\"]\n\ndef load_4bit_model(repo_or_path: str):\n    tok = AutoTokenizer.from_pretrained(\n        repo_or_path,\n        use_fast=True,\n        trust_remote_code=True,\n        cache_dir=HF_CACHE_DIR,\n    )\n    if tok.pad_token is None:\n        tok.pad_token = tok.eos_token\n    tok.padding_side = \"left\"\n\n    mdl = AutoModelForCausalLM.from_pretrained(\n        repo_or_path,\n        device_map=\"auto\",\n        torch_dtype=torch.bfloat16,\n        quantization_config=bnb4,\n        trust_remote_code=True,\n        attn_implementation=\"sdpa\",\n        cache_dir=HF_CACHE_DIR,\n    )\n    mdl.eval()\n    return tok, mdl\n\ndef load_fingpt(adapter_repo: str, base_repo: str):\n    tok, base = load_4bit_model(base_repo)\n    mdl = PeftModel.from_pretrained(base, adapter_repo)\n    mdl.eval()\n    return tok, mdl\n\n@torch.no_grad()\ndef generate_batch(tok, mdl, prompts, max_new_tokens=320):\n    enc = tok(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(mdl.device)\n    out = mdl.generate(\n        **enc,\n        max_new_tokens=max_new_tokens,\n        do_sample=False,\n        temperature=0.0,\n        top_p=1.0,\n        repetition_penalty=1.05,\n        pad_token_id=tok.eos_token_id,\n    )\n    return tok.batch_decode(out, skip_special_tokens=True)\n\nprint(\"Model utils ready. HF_CACHE_DIR =\", HF_CACHE_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T04:52:13.986861Z","iopub.execute_input":"2026-01-21T04:52:13.987080Z","iopub.status.idle":"2026-01-21T04:52:45.620273Z","shell.execute_reply.started":"2026-01-21T04:52:13.987057Z","shell.execute_reply":"2026-01-21T04:52:45.619815Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n2026-01-21 04:52:29.746153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768971150.096521     106 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768971150.211812     106 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768971151.075415     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768971151.075448     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768971151.075451     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768971151.075453     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Model utils ready. HF_CACHE_DIR = /dev/shm/kaggle_ram/hf/hub\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# CELL 5 (REPLACE) — teacher cell: không hardcode token + TEACH_CACHE_DIR dùng RAM\nfrom huggingface_hub import login\n\nHF_TOKEN = os.getenv(\"HF_TOKEN\", None)\nif HF_TOKEN:\n    login(token=HF_TOKEN)\n    print(\"HF login OK\")\nelse:\n    print(\"HF_TOKEN missing -> gated teachers may fail\")\n\nTEACH_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n\ndef run_teacher(name, repo=None, adapter=None, base=None, batch_size=16):\n    print(f\"\\n=== Teacher: {name} ===\")\n    try:\n        if adapter and base:\n            tok, mdl = load_fingpt(adapter, base)\n        else:\n            tok, mdl = load_4bit_model(repo)\n\n        with open(kd_pool_path, \"r\", encoding=\"utf-8\") as f:\n            pool = [json.loads(x) for x in f]\n\n        out_path = TEACH_CACHE_DIR / f\"{name}.jsonl\"\n        with open(out_path, \"w\", encoding=\"utf-8\") as fw:\n            for i in range(0, len(pool), batch_size):\n                batch = pool[i:i+batch_size]\n                prompts = [build_prompt(ex[\"task\"], ex[\"input\"]) for ex in batch]\n                texts = generate_batch(tok, mdl, prompts)\n\n                for ex, t in zip(batch, texts):\n                    fw.write(json.dumps({\"id\": ex[\"id\"], \"task\": ex[\"task\"], \"raw\": t}, ensure_ascii=False) + \"\\n\")\n\n        del mdl\n        torch.cuda.empty_cache()\n        print(\"Saved:\", str(out_path))\n        return str(out_path)\n    except Exception as e:\n        print(\"FAILED:\", name, \"| reason:\", str(e))\n        return None\n\n\nteacher_paths = {}\n\n# finance llama3 (public)\nteacher_paths[\"finance_llama3_8b\"] = run_teacher(\"finance_llama3_8b\", repo=TEACHERS[\"finance_llama3_8b\"])\n\n# open finance (gated)\nteacher_paths[\"open_finance_8b\"] = run_teacher(\"open_finance_8b\", repo=TEACHERS[\"open_finance_8b\"])\n\n# fingpt lora (needs base llama3 gated)\nteacher_paths[\"fingpt_lora_llama3_8b\"] = run_teacher(\n    \"fingpt_lora_llama3_8b\",\n    adapter=TEACHERS[\"fingpt_lora_llama3_8b\"],\n    base=FINGPT_BASE\n)\n\nprint(\"\\nTeacher paths:\", teacher_paths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T04:52:45.621031Z","iopub.execute_input":"2026-01-21T04:52:45.621560Z","iopub.status.idle":"2026-01-21T05:01:57.943862Z","shell.execute_reply.started":"2026-01-21T04:52:45.621539Z","shell.execute_reply":"2026-01-21T05:01:57.943367Z"}},"outputs":[{"name":"stdout","text":"HF_TOKEN missing -> gated teachers may fail\n\n=== Teacher: finance_llama3_8b ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d771b60a915f4b5abd01bf7aaff3207d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b5b2f61af1f434b818dc5ea5cce28bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76dd803eecff4916985e23bfecdb176d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/705 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db0d20c87f8347daa292aa62f8c68a7b"}},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d30e021430d74ce5be7e7ba110cf76e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1765bccfa1541c18348214fd3f9bbf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"244336a33379418980324c1652decfc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee81e9922a3542b49cb6bc9cbf3d4a53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"920ffe69929c4eb29c7f00b3c1328ac7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eefb591136824fff8d74e79b35e9940b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"949ef97d1bff4d6bb4a08e8bb050a6a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00007.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a70bd5f4303d47fbbc869ed98d3bc023"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00007.safetensors:   0%|          | 0.00/2.57G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"446640107f1344b5b32e71618544c91e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d38411ab5944a4a887f85c0f258bd74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d8bcbd3cf8a4772ba93a2e9c0864d09"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nThe following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"Saved: /dev/shm/kaggle_ram/working/teacher_outputs/finance_llama3_8b.jsonl\n\n=== Teacher: open_finance_8b ===\nFAILED: open_finance_8b | reason: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/DragonLLM/Llama-Open-Finance-8B.\n401 Client Error. (Request ID: Root=1-69705dc5-5c7ba9185031cad737268a6d;2f453635-a6be-4dd5-ba03-e22e5445c7ce)\n\nCannot access gated repo for url https://huggingface.co/DragonLLM/Llama-Open-Finance-8B/resolve/main/config.json.\nAccess to model DragonLLM/Llama-Open-Finance-8B is restricted. You must have access to it and be authenticated to access it. Please log in.\n\n=== Teacher: fingpt_lora_llama3_8b ===\nFAILED: fingpt_lora_llama3_8b | reason: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3-8B.\n401 Client Error. (Request ID: Root=1-69705dc5-0a5274bc78f5bc736aac4723;f3658477-5244-42ce-8ed8-abba4257fc75)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-3-8B is restricted. You must have access to it and be authenticated to access it. Please log in.\n\nTeacher paths: {'finance_llama3_8b': '/dev/shm/kaggle_ram/working/teacher_outputs/finance_llama3_8b.jsonl', 'open_finance_8b': None, 'fingpt_lora_llama3_8b': None}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def load_teacher_outputs(path):\n    out = {}\n    if not path:\n        return out\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            r = json.loads(line)\n            out[r[\"id\"]] = r\n    return out\n\nteacher_outputs = {k: load_teacher_outputs(v) for k,v in teacher_paths.items() if v}\n\ndef router_priority(task):\n    if task in [\"receipt_extract_text\", \"invoice_extract_text\"]:\n        return [\"open_finance_8b\", \"finance_llama3_8b\", \"fingpt_lora_llama3_8b\"]\n    if task == \"journal_from_structured_txn\":\n        return [\"finance_llama3_8b\", \"open_finance_8b\", \"fingpt_lora_llama3_8b\"]\n    return [\"finance_llama3_8b\", \"open_finance_8b\", \"fingpt_lora_llama3_8b\"]\n\ndistilled = []\ndropped = 0\npicked = {}\n\nwith open(kd_pool_path, \"r\", encoding=\"utf-8\") as f:\n    pool = [json.loads(x) for x in f]\n\nfor ex in pool:\n    task = ex[\"task\"]\n    cid  = ex[\"id\"]\n\n    chosen_obj = None\n    chosen_teacher = None\n\n    for tname in router_priority(task):\n        if tname not in teacher_outputs:\n            continue\n        rec = teacher_outputs[tname].get(cid)\n        if not rec:\n            continue\n\n        raw = rec[\"raw\"]\n        obj = extract_json_from_text(raw)\n        if obj is None:\n            obj = json_repair_minimal(raw)\n\n        if obj is not None and schema_pass(task, obj):\n            chosen_obj = obj\n            chosen_teacher = tname\n            break\n\n    if chosen_obj is None:\n        dropped += 1\n        continue\n\n    picked[chosen_teacher] = picked.get(chosen_teacher, 0) + 1\n    distilled.append({\n        \"id\": cid,\n        \"task\": task,\n        \"prompt\": build_prompt(task, ex[\"input\"]),\n        \"answer_json\": chosen_obj\n    })\n\nprint(\"KD distilled:\", len(distilled), \"| dropped:\", dropped)\nprint(\"picked_by_teacher:\", picked)\n\ndistill_path = str(DATA_DIR / \"distilled_train.jsonl\")\nwith open(distill_path, \"w\", encoding=\"utf-8\") as f:\n    for r in distilled:\n        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n\nprint(\"Saved:\", distill_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T05:01:57.944498Z","iopub.execute_input":"2026-01-21T05:01:57.944947Z","iopub.status.idle":"2026-01-21T05:01:58.442881Z","shell.execute_reply.started":"2026-01-21T05:01:57.944929Z","shell.execute_reply":"2026-01-21T05:01:58.442385Z"}},"outputs":[{"name":"stdout","text":"KD distilled: 0 | dropped: 450\npicked_by_teacher: {}\nSaved: /dev/shm/kaggle_ram/working/data/distilled_train.jsonl\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from datasets import Dataset\nfrom peft import LoraConfig, get_peft_model\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\n\nassert QWEN32B_PATH is not None, \"Cannot find Qwen3-32B in /kaggle/input\"\n\n# Load Qwen base\nqwen_tok, qwen_base = load_4bit_model(QWEN32B_PATH)\n\n# Auto-target modules (robust across architectures)\ndef guess_lora_targets(model):\n    names = set()\n    for n, _ in model.named_modules():\n        if any(k in n for k in [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]):\n            names.add(n.split(\".\")[-1])\n    # fallback default\n    if not names:\n        return [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"]\n    return sorted(list(names))\n\ntargets = guess_lora_targets(qwen_base)\nprint(\"LoRA targets:\", targets)\n\nlora_cfg = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=targets\n)\n\nstudent = get_peft_model(qwen_base, lora_cfg)\nstudent.print_trainable_parameters()\n\n# Prepare dataset\nrows = []\nwith open(distill_path, \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        r = json.loads(line)\n        rows.append({\n            \"text\": r[\"prompt\"] + \"\\n\\n\" + json.dumps(r[\"answer_json\"], ensure_ascii=False)\n        })\n\ntrain_ds = Dataset.from_list(rows)\n\nargs = TrainingArguments(\n    output_dir=str(WORKDIR / \"student_ckpt\"),\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=8,\n    learning_rate=2e-4,\n    num_train_epochs=1,\n    logging_steps=10,\n    save_steps=200,\n    bf16=True,\n    optim=\"paged_adamw_8bit\",\n    report_to=\"none\"\n)\n\ntrainer = SFTTrainer(\n    model=student,\n    tokenizer=qwen_tok,\n    train_dataset=train_ds,\n    args=args,\n    max_seq_length=2048,\n)\n\ntrainer.train()\n\nADAPTER_DIR = str(WORKDIR / \"student_adapter\")\ntrainer.model.save_pretrained(ADAPTER_DIR)\nqwen_tok.save_pretrained(ADAPTER_DIR)\n\nprint(\"Saved student adapter:\", ADAPTER_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T05:01:58.444025Z","iopub.execute_input":"2026-01-21T05:01:58.444403Z","iopub.status.idle":"2026-01-21T05:12:21.076863Z","shell.execute_reply.started":"2026-01-21T05:01:58.444386Z","shell.execute_reply":"2026-01-21T05:12:21.076282Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf552db474264605869ccb97916186e2"}},"metadata":{}},{"name":"stdout","text":"LoRA targets: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\ntrainable params: 134,217,728 || all params: 32,896,340,992 || trainable%: 0.4080\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_106/1127086778.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m trainer = SFTTrainer(\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqwen_tok\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: SFTTrainer.__init__() got an unexpected keyword argument 'tokenizer'"],"ename":"TypeError","evalue":"SFTTrainer.__init__() got an unexpected keyword argument 'tokenizer'","output_type":"error"}],"execution_count":10},{"cell_type":"code","source":"def normalize_obj(obj):\n    if obj is None:\n        return None\n    # stable dump for determinism comparison\n    return json.dumps(obj, ensure_ascii=False, sort_keys=True)\n\ndef field_exact(gold, pred, key):\n    if gold is None or pred is None:\n        return None\n    if gold.get(key) is None:\n        return None\n    return 1.0 if str(gold.get(key)).strip() == str(pred.get(key)).strip() else 0.0\n\ndef eval_model(tok, mdl, cases, repeats=3, batch_size=8):\n    stats = {\n        \"json_valid_rate\": 0,\n        \"schema_pass_rate\": 0,\n        \"determinism_rate\": 0,\n        \"n\": len(cases),\n        \"field_vendor_acc\": [],\n        \"field_total_acc\": [],\n        \"field_date_acc\": [],\n    }\n\n    det_same = 0\n    valid = 0\n    schema_ok = 0\n\n    for i in range(0, len(cases), batch_size):\n        batch = cases[i:i+batch_size]\n        prompts = [build_prompt(ex[\"task\"], ex[\"input\"]) for ex in batch]\n\n        # determinism: run repeats times\n        outputs_all = []\n        for _ in range(repeats):\n            texts = generate_batch(tok, mdl, prompts, max_new_tokens=320)\n            objs = []\n            for ex, t in zip(batch, texts):\n                obj = extract_json_from_text(t) or json_repair_minimal(t)\n                objs.append(obj)\n            outputs_all.append(objs)\n\n        # compute per-sample stats\n        for j, ex in enumerate(batch):\n            task = ex[\"task\"]\n            gold = ex.get(\"gold\")\n\n            # use first run as \"pred\"\n            pred = outputs_all[0][j]\n\n            if pred is not None:\n                valid += 1\n                if schema_pass(task, pred):\n                    schema_ok += 1\n\n            # determinism check: all normalized equal\n            norms = [normalize_obj(outputs_all[r][j]) for r in range(repeats)]\n            if len(set(norms)) == 1:\n                det_same += 1\n\n            # Tier B field acc if gold exists & relevant\n            if gold and isinstance(gold, dict) and task in [\"receipt_extract_text\",\"invoice_extract_text\"]:\n                v = field_exact(gold, pred, \"vendor_name\")\n                d = field_exact(gold, pred, \"date\")\n                # receipt: total_amount ; invoice: total\n                if task == \"receipt_extract_text\":\n                    tacc = field_exact(gold, pred, \"total_amount\")\n                else:\n                    tacc = field_exact(gold, pred, \"total\")\n\n                if v is not None: stats[\"field_vendor_acc\"].append(v)\n                if d is not None: stats[\"field_date_acc\"].append(d)\n                if tacc is not None: stats[\"field_total_acc\"].append(tacc)\n\n    n = max(1, stats[\"n\"])\n    stats[\"json_valid_rate\"] = valid / n\n    stats[\"schema_pass_rate\"] = schema_ok / n\n    stats[\"determinism_rate\"] = det_same / n\n\n    def avg(x):\n        return float(sum(x)/len(x)) if x else None\n\n    stats[\"vendor_acc\"] = avg(stats[\"field_vendor_acc\"])\n    stats[\"date_acc\"] = avg(stats[\"field_date_acc\"])\n    stats[\"total_acc\"] = avg(stats[\"field_total_acc\"])\n\n    # cleanup arrays\n    stats.pop(\"field_vendor_acc\", None)\n    stats.pop(\"field_date_acc\", None)\n    stats.pop(\"field_total_acc\", None)\n\n    return stats\n\n# Load eval cases\nwith open(eval_path, \"r\", encoding=\"utf-8\") as f:\n    eval_cases = [json.loads(x) for x in f]\n\n# BASE QWEN\nbase_tok, base_mdl = load_4bit_model(QWEN32B_PATH)\nbase_stats = eval_model(base_tok, base_mdl, eval_cases, repeats=3)\nprint(\"BASE:\", base_stats)\n\n# STUDENT = base + adapter\nfrom peft import PeftModel\nstudent_tok, student_base = load_4bit_model(QWEN32B_PATH)\nstudent_mdl = PeftModel.from_pretrained(student_base, ADAPTER_DIR)\nstudent_mdl.eval()\nstudent_stats = eval_model(student_tok, student_mdl, eval_cases, repeats=3)\nprint(\"STUDENT:\", student_stats)\n\nreport = {\n    \"base_qwen3_32b\": base_stats,\n    \"student_qwen3_32b_adapter\": student_stats,\n}\n\nreport_path = str(DATA_DIR / \"eval_report.json\")\nwith open(report_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(report, f, ensure_ascii=False, indent=2)\n\nprint(\"Saved report:\", report_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T05:12:21.077362Z","iopub.status.idle":"2026-01-21T05:12:21.077530Z","shell.execute_reply.started":"2026-01-21T05:12:21.077448Z","shell.execute_reply":"2026-01-21T05:12:21.077459Z"}},"outputs":[],"execution_count":null}]}