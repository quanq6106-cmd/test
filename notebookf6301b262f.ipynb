{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":118448,"databundleVersionId":14559231,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":3424966,"sourceType":"datasetVersion","datasetId":2035671},{"sourceId":3818163,"sourceType":"datasetVersion","datasetId":2274483},{"sourceId":4501486,"sourceType":"datasetVersion","datasetId":2631784},{"sourceId":5258124,"sourceType":"datasetVersion","datasetId":3059801},{"sourceId":9971715,"sourceType":"datasetVersion","datasetId":6134857},{"sourceId":11087772,"sourceType":"datasetVersion","datasetId":4576291},{"sourceId":11497644,"sourceType":"datasetVersion","datasetId":7207743},{"sourceId":11564740,"sourceType":"datasetVersion","datasetId":7251054},{"sourceId":11739593,"sourceType":"datasetVersion","datasetId":5773627},{"sourceId":363168,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":301540,"modelId":322000}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# CELL 2 (REPLACE) — install xong KHÔNG import transformers ở đây (để tránh cache về disk trước)\n!pip -q install -U --no-cache-dir \\\n  \"transformers>=4.51.0\" \\\n  \"accelerate>=0.30.0\" \\\n  \"datasets>=2.19.0\" \\\n  \"peft>=0.11.0\" \\\n  \"trl>=0.9.6\" \\\n  \"bitsandbytes>=0.43.1\" \\\n  \"huggingface_hub>=0.23.0\" \\\n  \"tokenizers>=0.21.0\" \\\n  \"safetensors>=0.4.3\" \\\n  \"sentencepiece\" \\\n  \"jsonschema>=4.22.0\" \\\n  \"rapidfuzz>=3.9.0\" \\\n  \"openpyxl>=3.1.5\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:49:41.538318Z","iopub.execute_input":"2026-01-21T15:49:41.538517Z","iopub.status.idle":"2026-01-21T15:50:01.153841Z","shell.execute_reply.started":"2026-01-21T15:49:41.538502Z","shell.execute_reply":"2026-01-21T15:50:01.153376Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m239.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m605.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.2/515.2 kB\u001b[0m \u001b[31m604.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.0/557.0 kB\u001b[0m \u001b[31m616.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/532.5 kB\u001b[0m \u001b[31m562.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m251.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m286.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.2/507.2 kB\u001b[0m \u001b[31m616.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m503.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m281.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nray 2.52.1 requires click!=8.3.*,>=7.0, but you have click 8.3.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# CELL 1 (REPLACE) — RAM mode phải chạy TRƯỚC MỌI import transformers/tokenizers/peft\nimport os\nfrom pathlib import Path\n\n!df -h /dev/shm\n\nRAM_BASE = Path(\"/dev/shm/kaggle_ram\")\nRAM_BASE.mkdir(parents=True, exist_ok=True)\n\nHF_HOME = RAM_BASE / \"hf\"\nHF_HOME.mkdir(parents=True, exist_ok=True)\n\nos.environ[\"HF_HOME\"] = str(HF_HOME)\nos.environ[\"HF_HUB_CACHE\"] = str(HF_HOME / \"hub\")\nos.environ[\"HF_DATASETS_CACHE\"] = str(HF_HOME / \"datasets\")\nos.environ[\"TRANSFORMERS_CACHE\"] = str(HF_HOME / \"transformers\")\nos.environ[\"TORCH_HOME\"] = str(RAM_BASE / \"torch\")\nos.environ[\"XDG_CACHE_HOME\"] = str(RAM_BASE / \".cache\")\n\n# outputs/logs cũng đẩy vào RAM\nWORKDIR = RAM_BASE / \"working\"\nDATA_DIR = WORKDIR / \"data\"\nTEACH_CACHE_DIR = WORKDIR / \"teacher_outputs\"\nWORKDIR.mkdir(parents=True, exist_ok=True)\nDATA_DIR.mkdir(parents=True, exist_ok=True)\nTEACH_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"HF_HOME =\", os.environ[\"HF_HOME\"])\nprint(\"HF_HUB_CACHE =\", os.environ[\"HF_HUB_CACHE\"])\nprint(\"WORKDIR =\", WORKDIR)\nprint(\"DATA_DIR =\", DATA_DIR)\nprint(\"TEACH_CACHE_DIR =\", TEACH_CACHE_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:50:01.154813Z","iopub.execute_input":"2026-01-21T15:50:01.154957Z","iopub.status.idle":"2026-01-21T15:50:01.271349Z","shell.execute_reply.started":"2026-01-21T15:50:01.154934Z","shell.execute_reply":"2026-01-21T15:50:01.270895Z"}},"outputs":[{"name":"stdout","text":"Filesystem      Size  Used Avail Use% Mounted on\nshm             114G     0  114G   0% /dev/shm\nHF_HOME = /dev/shm/kaggle_ram/hf\nHF_HUB_CACHE = /dev/shm/kaggle_ram/hf/hub\nWORKDIR = /dev/shm/kaggle_ram/working\nDATA_DIR = /dev/shm/kaggle_ram/working/data\nTEACH_CACHE_DIR = /dev/shm/kaggle_ram/working/teacher_outputs\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# CELL 3 (REPLACE) — setup PATHS/QWEN32B_PATH nhưng KHÔNG reset WORKDIR/DATA_DIR về /kaggle/working nữa\nimport os, re, json, time, math, random\nfrom glob import glob\n\n# WORKDIR/DATA_DIR đã được set từ CELL 1 (RAM). Không ghi đè lại.\nDATA_DIR.mkdir(parents=True, exist_ok=True)\n\ndef find_qwen32b_path():\n    candidates = []\n    for p in glob(\"/kaggle/input/**\", recursive=True):\n        if os.path.isdir(p):\n            low = p.lower()\n            if \"qwen\" in low and (\"32b\" in low or \"32-b\" in low):\n                if os.path.exists(os.path.join(p, \"config.json\")):\n                    candidates.append(p)\n    candidates = sorted(candidates, key=lambda x: len(x))\n    return candidates[0] if candidates else None\n\nQWEN32B_PATH = find_qwen32b_path()\nprint(\"QWEN32B_PATH =\", QWEN32B_PATH)\n\nTEACHERS = {\n    \"open_finance_8b\": \"DragonLLM/Llama-Open-Finance-8B\",\n    \"finance_llama3_8b\": \"instruction-pretrain/finance-Llama3-8B\",\n    \"fingpt_lora_llama3_8b\": \"FinGPT/fingpt-mt_llama3-8b_lora\",\n}\nFINGPT_BASE = \"meta-llama/Meta-Llama-3-8B\"\n\nPATHS = {\n    \"vn_mcocr\": \"/kaggle/input/vietnamese-receipts-mc-ocr-2021\",\n    \"invoice_ocr\": \"/kaggle/input/invoice-ocr\",\n    \"hi_quality_invoice\": \"/kaggle/input/high-quality-invoice-images-for-ocr\",\n    \"gl_xlsx\": \"/kaggle/input/generalledger/Data file for students.xlsx\",\n    \"transactions_csv\": \"/kaggle/input/financial-transactions-dataset/financial_transactions.csv\",\n    \"forecast_csv\": \"/kaggle/input/financial-forecasting-data/simulated_financial_forecasting_data.csv\",\n    \"data_retriever_csv\": \"/kaggle/input/data-retreiver/Data_ret.csv\",\n}\nprint(\"DATA PATHS OK\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:50:01.272027Z","iopub.execute_input":"2026-01-21T15:50:01.272160Z","iopub.status.idle":"2026-01-21T15:55:22.676657Z","shell.execute_reply.started":"2026-01-21T15:50:01.272144Z","shell.execute_reply":"2026-01-21T15:55:22.676251Z"}},"outputs":[{"name":"stdout","text":"QWEN32B_PATH = /kaggle/input/qwen-3/transformers/32b/1\nDATA PATHS OK\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from jsonschema import validate\nfrom jsonschema.exceptions import ValidationError\n\n# ===== Schemas =====\nRECEIPT_SCHEMA = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"vendor_name\": {\"type\": [\"string\", \"null\"]},\n        \"address\": {\"type\": [\"string\", \"null\"]},\n        \"date\": {\"type\": [\"string\", \"null\"]},            # YYYY-MM-DD preferred\n        \"total_amount\": {\"type\": [\"number\", \"null\"]},\n        \"currency\": {\"type\": [\"string\", \"null\"]},        # \"VND\"\n        \"confidence\": {\"type\": \"number\"},\n        \"flags\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n    },\n    \"required\": [\"vendor_name\",\"address\",\"date\",\"total_amount\",\"currency\",\"confidence\",\"flags\"]\n}\n\nINVOICE_SCHEMA = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"vendor_name\": {\"type\": [\"string\", \"null\"]},\n        \"invoice_no\": {\"type\": [\"string\", \"null\"]},\n        \"date\": {\"type\": [\"string\", \"null\"]},\n        \"subtotal\": {\"type\": [\"number\", \"null\"]},\n        \"tax\": {\"type\": [\"number\", \"null\"]},\n        \"total\": {\"type\": [\"number\", \"null\"]},\n        \"currency\": {\"type\": [\"string\", \"null\"]},\n        \"confidence\": {\"type\": \"number\"},\n        \"flags\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n    },\n    \"required\": [\"vendor_name\",\"invoice_no\",\"date\",\"subtotal\",\"tax\",\"total\",\"currency\",\"confidence\",\"flags\"]\n}\n\nJOURNAL_SCHEMA = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"entries\": {\n            \"type\": \"array\",\n            \"items\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"account\": {\"type\": \"string\"},\n                    \"debit\": {\"type\": \"number\"},\n                    \"credit\": {\"type\": \"number\"},\n                    \"memo\": {\"type\": [\"string\",\"null\"]}\n                },\n                \"required\": [\"account\",\"debit\",\"credit\",\"memo\"]\n            }\n        },\n        \"confidence\": {\"type\": \"number\"},\n        \"flags\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n    },\n    \"required\": [\"entries\",\"confidence\",\"flags\"]\n}\n\nTASK2SCHEMA = {\n    \"receipt_extract_text\": RECEIPT_SCHEMA,\n    \"invoice_extract_text\": INVOICE_SCHEMA,\n    \"journal_from_structured_txn\": JOURNAL_SCHEMA,\n}\n\ndef schema_pass(task: str, obj: dict) -> bool:\n    try:\n        validate(instance=obj, schema=TASK2SCHEMA[task])\n        return True\n    except ValidationError:\n        return False\n    except Exception:\n        return False\n\n# ===== JSON extract / repair =====\ndef extract_json_from_text(text: str):\n    if text is None:\n        return None\n    # pick first {...} block\n    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n    if not m:\n        return None\n    s = m.group(0)\n    try:\n        return json.loads(s)\n    except Exception:\n        return None\n\ndef json_repair_minimal(text: str):\n    \"\"\"\n    deterministic repair for common LLM issues:\n    - trailing commas\n    - single quotes -> double quotes (simple cases)\n    \"\"\"\n    if text is None:\n        return None\n    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n    if not m:\n        return None\n    s = m.group(0).strip()\n\n    s = re.sub(r\",\\s*}\", \"}\", s)\n    s = re.sub(r\",\\s*]\", \"]\", s)\n    # naive quote fix (only if it looks like JSON)\n    if \"'\" in s and '\"' not in s:\n        s = s.replace(\"'\", '\"')\n\n    try:\n        return json.loads(s)\n    except Exception:\n        return None\n\n# ===== Prompt builder =====\ndef build_prompt(task: str, input_data):\n    if task == \"receipt_extract_text\":\n        return f\"\"\"\nExtract receipt key fields from Vietnamese text.\nReturn ONLY valid JSON with fields:\nvendor_name,address,date,total_amount,currency,confidence,flags\n\nReceipt Text:\n{input_data}\n\"\"\".strip()\n\n    if task == \"invoice_extract_text\":\n        return f\"\"\"\nExtract invoice fields from text.\nReturn ONLY valid JSON with fields:\nvendor_name,invoice_no,date,subtotal,tax,total,currency,confidence,flags\n\nInvoice Text:\n{input_data}\n\"\"\".strip()\n\n    if task == \"journal_from_structured_txn\":\n        return f\"\"\"\nYou are an ERP accountant.\nGiven a structured transaction JSON, propose journal entries.\nReturn ONLY valid JSON with fields:\n- entries: array of objects (account, debit, credit, memo)\n- confidence\n- flags\n\nTransaction:\n{json.dumps(input_data, ensure_ascii=False)}\n\"\"\".strip()\n\n    raise ValueError(\"Unknown task\")\n\nprint(\"Schemas + prompt builder ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:55:22.677283Z","iopub.execute_input":"2026-01-21T15:55:22.677639Z","iopub.status.idle":"2026-01-21T15:55:23.454798Z","shell.execute_reply.started":"2026-01-21T15:55:22.677626Z","shell.execute_reply":"2026-01-21T15:55:23.454423Z"}},"outputs":[{"name":"stdout","text":"Schemas + prompt builder ready.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\ndef infer_col(df, candidates):\n    cols = {c.lower(): c for c in df.columns}\n    for cand in candidates:\n        if cand.lower() in cols:\n            return cols[cand.lower()]\n    # fuzzy contains\n    for c in df.columns:\n        low = c.lower()\n        for cand in candidates:\n            if cand.lower() in low:\n                return c\n    return None\n\ndef load_vn_mcocr_cases(limit=300):\n    root = PATHS[\"vn_mcocr\"]\n    cases = []\n\n    # Prefer CSV with gold labels if present\n    csv_candidates = [\n        os.path.join(root, \"mcocr_train_df.csv\"),\n        os.path.join(root, \"mcocr_val_sample_df.csv\"),\n        os.path.join(root, \"results.csv\"),\n    ]\n    for p in csv_candidates:\n        if os.path.exists(p):\n            df = pd.read_csv(p)\n\n            text_col = infer_col(df, [\"text\", \"ocr_text\", \"raw_text\", \"content\", \"transcription\"])\n            if text_col is None:\n                # fallback pick longest string col\n                str_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n                if str_cols:\n                    text_col = max(str_cols, key=lambda c: df[c].astype(str).str.len().mean())\n\n            seller_col = infer_col(df, [\"seller\", \"vendor\", \"vendor_name\", \"merchant\", \"store\", \"shop\"])\n            addr_col   = infer_col(df, [\"address\", \"seller_address\", \"vendor_address\"])\n            date_col   = infer_col(df, [\"timestamp\", \"date\", \"datetime\", \"time\"])\n            total_col  = infer_col(df, [\"total_cost\", \"total\", \"amount\", \"total_amount\", \"sum\"])\n\n            for i, row in df.head(limit).iterrows():\n                raw_text = str(row[text_col]) if text_col else \"\"\n\n                gold = None\n                if seller_col or addr_col or date_col or total_col:\n                    def safe_float(x):\n                        try:\n                            if pd.isna(x): \n                                return None\n                            s = str(x)\n                            s = re.sub(r\"[^\\d\\.\\-]\", \"\", s)\n                            return float(s) if s else None\n                        except:\n                            return None\n\n                    gold = {\n                        \"vendor_name\": str(row[seller_col]) if seller_col and pd.notna(row[seller_col]) else None,\n                        \"address\": str(row[addr_col]) if addr_col and pd.notna(row[addr_col]) else None,\n                        \"date\": str(row[date_col]) if date_col and pd.notna(row[date_col]) else None,\n                        \"total_amount\": safe_float(row[total_col]) if total_col else None,\n                        \"currency\": \"VND\",\n                        \"confidence\": 0.0,\n                        \"flags\": []\n                    }\n\n                cases.append({\n                    \"id\": f\"vn_mcocr_{i}\",\n                    \"task\": \"receipt_extract_text\",\n                    \"input\": raw_text,\n                    \"gold\": gold,\n                    \"meta\": {\"source\": os.path.basename(p)}\n                })\n            return cases\n\n    # fallback txt (OCR lines)\n    txt_candidates = [\n        os.path.join(root, \"text_recognition_train_data.txt\"),\n        os.path.join(root, \"text_recognition_val_data.txt\"),\n    ]\n    for p in txt_candidates:\n        if os.path.exists(p):\n            with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n                for idx, line in enumerate(f):\n                    if idx >= limit:\n                        break\n                    parts = line.strip().split(\"\\t\")\n                    raw_text = parts[-1] if parts else \"\"\n                    cases.append({\n                        \"id\": f\"vn_mcocr_txt_{idx}\",\n                        \"task\": \"receipt_extract_text\",\n                        \"input\": raw_text,\n                        \"gold\": None,\n                        \"meta\": {\"source\": os.path.basename(p)}\n                    })\n            return cases\n\n    return []\n\ndef load_gl_cases(limit=200):\n    xlsx_path = PATHS[\"gl_xlsx\"]\n    if not os.path.exists(xlsx_path):\n        return []\n    xls = pd.ExcelFile(xlsx_path)\n    # take first sheet by default\n    df = pd.read_excel(xlsx_path, sheet_name=xls.sheet_names[0])\n\n    cases = []\n    for i, row in df.head(limit).iterrows():\n        txn = row.to_dict()\n        cases.append({\n            \"id\": f\"gl_{i}\",\n            \"task\": \"journal_from_structured_txn\",\n            \"input\": txn,\n            \"gold\": None,\n            \"meta\": {\"sheet\": xls.sheet_names[0]}\n        })\n    return cases\n\ndef load_invoice_ocr_cases(limit=200):\n    \"\"\"\n    Robust loader:\n    - If JSON/CSV annotations exist -> use their text fields\n    - Otherwise use image paths (text-only LLM can't read images, but still valid for KD if you later OCR)\n    \"\"\"\n    root = PATHS[\"invoice_ocr\"]\n    if not os.path.exists(root):\n        return []\n\n    ann_files = []\n    for ext in [\"*.json\",\"*.csv\"]:\n        ann_files += glob(os.path.join(root, \"**\", ext), recursive=True)\n\n    cases = []\n    if ann_files:\n        # take first annotation file found\n        p = ann_files[0]\n        if p.endswith(\".csv\"):\n            df = pd.read_csv(p)\n            text_col = infer_col(df, [\"text\",\"ocr\",\"raw\",\"content\"])\n            for i, row in df.head(limit).iterrows():\n                raw_text = str(row[text_col]) if text_col else \"\"\n                cases.append({\n                    \"id\": f\"invoice_ocr_csv_{i}\",\n                    \"task\": \"invoice_extract_text\",\n                    \"input\": raw_text,\n                    \"gold\": None,\n                    \"meta\": {\"ann\": os.path.basename(p)}\n                })\n        else:\n            with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n                js = json.load(f)\n            # try to find list items with \"text\"\n            items = []\n            if isinstance(js, list):\n                items = js\n            elif isinstance(js, dict):\n                # common keys\n                for k in [\"data\",\"items\",\"annotations\",\"samples\"]:\n                    if k in js and isinstance(js[k], list):\n                        items = js[k]\n                        break\n\n            for i, it in enumerate(items[:limit]):\n                raw_text = it.get(\"text\") or it.get(\"ocr_text\") or it.get(\"content\") or \"\"\n                cases.append({\n                    \"id\": f\"invoice_ocr_json_{i}\",\n                    \"task\": \"invoice_extract_text\",\n                    \"input\": str(raw_text),\n                    \"gold\": None,\n                    \"meta\": {\"ann\": os.path.basename(p)}\n                })\n\n        return cases\n\n    # fallback: use image paths (for later OCR pipeline)\n    imgs = glob(os.path.join(root, \"**\", \"*.png\"), recursive=True) + glob(os.path.join(root, \"**\", \"*.jpg\"), recursive=True)\n    for i, ip in enumerate(imgs[:limit]):\n        cases.append({\n            \"id\": f\"invoice_ocr_img_{i}\",\n            \"task\": \"invoice_extract_text\",\n            \"input\": f\"[IMAGE_PATH]{ip}\",\n            \"gold\": None,\n            \"meta\": {\"img\": os.path.basename(ip)}\n        })\n    return cases\n\nprint(\"Loaders ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:55:23.455832Z","iopub.execute_input":"2026-01-21T15:55:23.455965Z","iopub.status.idle":"2026-01-21T15:55:23.699187Z","shell.execute_reply.started":"2026-01-21T15:55:23.455952Z","shell.execute_reply":"2026-01-21T15:55:23.698759Z"}},"outputs":[{"name":"stdout","text":"Loaders ready.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime, date\n\ndef _json_default(o):\n    if isinstance(o, (pd.Timestamp, datetime, date)):\n        return o.isoformat()\n    if isinstance(o, (np.integer,)):\n        return int(o)\n    if isinstance(o, (np.floating,)):\n        return float(o)\n    if isinstance(o, (np.ndarray,)):\n        return o.tolist()\n    return str(o)\n\ndef write_jsonl(path, rows):\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        for r in rows:\n            f.write(json.dumps(r, ensure_ascii=False, default=_json_default) + \"\\n\")\n\n\neval_cases = []\neval_cases += load_vn_mcocr_cases(limit=300)\neval_cases += load_invoice_ocr_cases(limit=200)\neval_cases += load_gl_cases(limit=150)\n\nprint(\"Total eval cases:\", len(eval_cases))\neval_path = str(DATA_DIR / \"eval_cases.jsonl\")\nwrite_jsonl(eval_path, eval_cases)\nprint(\"Saved:\", eval_path)\n\n# KD training uses the same pool (you can enlarge later)\nkd_pool = eval_cases.copy()\nrandom.shuffle(kd_pool)\nkd_pool = kd_pool[:500]  # keep KD small for iteration speed\nkd_pool_path = str(DATA_DIR / \"kd_pool.jsonl\")\nwrite_jsonl(kd_pool_path, kd_pool)\nprint(\"Saved KD pool:\", kd_pool_path, \"| size:\", len(kd_pool))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:55:23.699726Z","iopub.execute_input":"2026-01-21T15:55:23.699895Z","iopub.status.idle":"2026-01-21T15:55:25.422507Z","shell.execute_reply.started":"2026-01-21T15:55:23.699882Z","shell.execute_reply":"2026-01-21T15:55:25.422096Z"}},"outputs":[{"name":"stdout","text":"Total eval cases: 450\nSaved: /dev/shm/kaggle_ram/working/data/eval_cases.jsonl\nSaved KD pool: /dev/shm/kaggle_ram/working/data/kd_pool.jsonl | size: 450\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# CELL 4 (REPLACE) — model utils: decode ONLY generated tokens (stop prompt-echo killing JSON parsing)\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import PeftModel\n\ntorch.backends.cuda.matmul.allow_tf32 = True\ntorch.backends.cudnn.allow_tf32 = True\n\nbnb4 = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n)\n\nHF_CACHE_DIR = os.environ[\"HF_HUB_CACHE\"]\n\ndef load_4bit_model(repo_or_path: str):\n    tok = AutoTokenizer.from_pretrained(\n        repo_or_path,\n        use_fast=True,\n        trust_remote_code=True,\n        cache_dir=HF_CACHE_DIR,\n    )\n    if tok.pad_token is None:\n        tok.pad_token = tok.eos_token\n    tok.padding_side = \"left\"\n\n    mdl = AutoModelForCausalLM.from_pretrained(\n        repo_or_path,\n        device_map=\"auto\",\n        torch_dtype=torch.bfloat16,\n        quantization_config=bnb4,\n        trust_remote_code=True,\n        attn_implementation=\"sdpa\",\n        cache_dir=HF_CACHE_DIR,\n    )\n    mdl.eval()\n    return tok, mdl\n\ndef load_fingpt(adapter_repo: str, base_repo: str):\n    tok, base = load_4bit_model(base_repo)\n    mdl = PeftModel.from_pretrained(base, adapter_repo)\n    mdl.eval()\n    return tok, mdl\n\n@torch.no_grad()\ndef generate_batch(tok, mdl, prompts, max_new_tokens=320):\n    enc = tok(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(mdl.device)\n    out = mdl.generate(\n        **enc,\n        max_new_tokens=max_new_tokens,\n        do_sample=False,\n        top_p=1.0,\n        repetition_penalty=1.05,\n        pad_token_id=tok.eos_token_id,\n    )\n    # ✅ decode only the newly generated tokens (avoid full prompt echo)\n    in_len = enc[\"input_ids\"].shape[1]\n    gen = out[:, in_len:]\n    return tok.batch_decode(gen, skip_special_tokens=True)\n\nprint(\"Model utils ready. HF_CACHE_DIR =\", HF_CACHE_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:55:25.423093Z","iopub.execute_input":"2026-01-21T15:55:25.423280Z","iopub.status.idle":"2026-01-21T15:55:56.780205Z","shell.execute_reply.started":"2026-01-21T15:55:25.423266Z","shell.execute_reply":"2026-01-21T15:55:56.779699Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n2026-01-21 15:55:41.505052: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769010941.856139     106 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769010941.975777     106 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769010942.934195     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769010942.934220     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769010942.934222     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769010942.934223     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Model utils ready. HF_CACHE_DIR = /dev/shm/kaggle_ram/hf/hub\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# CELL 5 (REPLACE) — teacher cell: không hardcode token + TEACH_CACHE_DIR dùng RAM\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nsecret_value_1 = user_secrets.get_secret(\"HF_TOKEN\")\n\nHF_TOKEN = os.getenv(\"HF_TOKEN\", secret_value_1)\nif HF_TOKEN:\n    login(token=HF_TOKEN)\n    print(\"HF login OK\")\nelse:\n    print(\"HF_TOKEN missing -> gated teachers may fail\")\n\nTEACH_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n\ndef run_teacher(name, repo=None, adapter=None, base=None, batch_size=16):\n    print(f\"\\n=== Teacher: {name} ===\")\n    try:\n        if adapter and base:\n            tok, mdl = load_fingpt(adapter, base)\n        else:\n            tok, mdl = load_4bit_model(repo)\n\n        with open(kd_pool_path, \"r\", encoding=\"utf-8\") as f:\n            pool = [json.loads(x) for x in f]\n\n        out_path = TEACH_CACHE_DIR / f\"{name}.jsonl\"\n        with open(out_path, \"w\", encoding=\"utf-8\") as fw:\n            for i in range(0, len(pool), batch_size):\n                batch = pool[i:i+batch_size]\n                prompts = [build_prompt(ex[\"task\"], ex[\"input\"]) for ex in batch]\n                texts = generate_batch(tok, mdl, prompts)\n\n                for ex, t in zip(batch, texts):\n                    fw.write(json.dumps({\"id\": ex[\"id\"], \"task\": ex[\"task\"], \"raw\": t}, ensure_ascii=False) + \"\\n\")\n\n        del mdl\n        torch.cuda.empty_cache()\n        print(\"Saved:\", str(out_path))\n        return str(out_path)\n    except Exception as e:\n        print(\"FAILED:\", name, \"| reason:\", str(e))\n        return None\n\n\nteacher_paths = {}\n\n# finance llama3 (public)\nteacher_paths[\"finance_llama3_8b\"] = run_teacher(\"finance_llama3_8b\", repo=TEACHERS[\"finance_llama3_8b\"])\n\n# open finance (gated)\nteacher_paths[\"open_finance_8b\"] = run_teacher(\"open_finance_8b\", repo=TEACHERS[\"open_finance_8b\"])\n\n# fingpt lora (needs base llama3 gated)\nteacher_paths[\"fingpt_lora_llama3_8b\"] = run_teacher(\n    \"fingpt_lora_llama3_8b\",\n    adapter=TEACHERS[\"fingpt_lora_llama3_8b\"],\n    base=FINGPT_BASE\n)\n\nprint(\"\\nTeacher paths:\", teacher_paths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:55:56.780831Z","iopub.execute_input":"2026-01-21T15:55:56.781215Z","iopub.status.idle":"2026-01-21T16:13:05.083455Z","shell.execute_reply.started":"2026-01-21T15:55:56.781199Z","shell.execute_reply":"2026-01-21T16:13:05.083022Z"}},"outputs":[{"name":"stdout","text":"HF login OK\n\n=== Teacher: finance_llama3_8b ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96d316221dad4be5b5b87006b7c96d70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53df9398e39f41e9922aa3591154db6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed276cb3a8294692bcb096e0823e90ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/705 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66746812516b4e559e27f1f662e3d6d2"}},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17a68162bcc745bfa8057ecfa6fe6e16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26a9eeb183a445f4990c6bc9063e327f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00007.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8b2ff771e3e4722929adedb7f2ea031"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f32e6ff622aa438b8bf7cb812c35839a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00007.safetensors:   0%|          | 0.00/2.57G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0fb9c41ffa94ce2a3a18d691e18f3c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91e32a6aa05d47bd9549b8631ad42b0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"545861b00a71483e824e95c95f27e5ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8707859d418248358ae4337917f291fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30ef528da9c74b29a99df397bc7007cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4abe024e4663402f974dc4bc4d2fac66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b0907ed9e7347beafab4a767568ea53"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nThe following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"Saved: /dev/shm/kaggle_ram/working/teacher_outputs/finance_llama3_8b.jsonl\n\n=== Teacher: open_finance_8b ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"781767fd70c143c88777de11169a41f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84d0fc6606554fd59e33c79e5948fc2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/439 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c636a1517a442bd854f112a0c1c55cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja:   0%|          | 0.00/4.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d02a8d251f34ee0b038cca415b644f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/860 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13c11c06c3044e18aca2d3e9755fa9ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/24.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b512738294d8413f97d536a4e1ac37ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd052284ad86424db908725ad978e917"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b71831faa35411f9778db6adfbf10b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50194b6f72d1473a85c660d70726afee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ec0456e3cd94c068fcdaaf8083fb2e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d54d2b401714770821b13e92de003e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1d197cdd911491cbb5cedb26eb3eabb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00007.safetensors:   0%|          | 0.00/2.57G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"effda0d28bb34b9e99ee3cb9c3587c8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00007.safetensors:   0%|          | 0.00/4.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"429833b15c514ea3bcf96ba67ebe4fb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22ae60a6ba0f4c2698c4eed8ad151392"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49078aa5209143a5938c7e5229de033c"}},"metadata":{}},{"name":"stdout","text":"Saved: /dev/shm/kaggle_ram/working/teacher_outputs/open_finance_8b.jsonl\n\n=== Teacher: fingpt_lora_llama3_8b ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"071347ed4d3e4add819613a9d81fe047"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b2654cbdf3648ec95c185584fe0b8c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4a6d78d45b2416abaf2345930f401e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bd3de1d7b1740fb967dd6807e39accc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5b254fab324429f98086f94ea7894c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c646e308e2f456ea0ced152f044ce51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6dc15744e83440ba579259a27d43b98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89ba46992b1f4bb8bdbed12c139eeb76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4211b5273ac24aa5b757cdcb091567c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d5f31cb60344d259c23cbcb073e49e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"287524c77f054839b36bd4aa5aba6aba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ed7e7ed0d354444b94ae8a6b4fa8226"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f9a4960d105486b888722f8c71257ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/13.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2770680c4ddd4721916e042d2f5bf302"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"Saved: /dev/shm/kaggle_ram/working/teacher_outputs/fingpt_lora_llama3_8b.jsonl\n\nTeacher paths: {'finance_llama3_8b': '/dev/shm/kaggle_ram/working/teacher_outputs/finance_llama3_8b.jsonl', 'open_finance_8b': '/dev/shm/kaggle_ram/working/teacher_outputs/open_finance_8b.jsonl', 'fingpt_lora_llama3_8b': '/dev/shm/kaggle_ram/working/teacher_outputs/fingpt_lora_llama3_8b.jsonl'}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# CELL DISTILL (REPLACE) — robust JSON extraction + coercion so KD distilled != 0\nimport re, json\nfrom datetime import datetime\n\ndef _strip_code_fences(s: str) -> str:\n    if not s:\n        return s\n    s = s.strip()\n    # remove ```json ... ``` or ``` ... ```\n    s = re.sub(r\"^```(?:json)?\\s*\", \"\", s, flags=re.I)\n    s = re.sub(r\"\\s*```$\", \"\", s)\n    return s.strip()\n\ndef _try_json_load(s: str):\n    try:\n        return json.loads(s)\n    except Exception:\n        return None\n\ndef _json_repair_minimal(s: str):\n    if s is None:\n        return None\n    s = _strip_code_fences(s)\n    s = s.strip()\n\n    # remove trailing commas\n    s = re.sub(r\",\\s*}\", \"}\", s)\n    s = re.sub(r\",\\s*]\", \"]\", s)\n\n    # if single quotes and no double quotes (naive)\n    if \"'\" in s and '\"' not in s:\n        s = s.replace(\"'\", '\"')\n\n    return _try_json_load(s)\n\ndef extract_json_robust(text: str):\n    \"\"\"\n    Strategy:\n    1) try whole text (after stripping fences)\n    2) try JSON code block\n    3) scan all {...} candidates and pick the first that parses\n    \"\"\"\n    if text is None:\n        return None\n\n    t = _strip_code_fences(text)\n\n    # 1) whole\n    obj = _try_json_load(t)\n    if obj is not None:\n        return obj\n\n    # 2) try inside ```json ... ```\n    m = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", text, flags=re.S | re.I)\n    if m:\n        obj = _try_json_load(m.group(1))\n        if obj is not None:\n            return obj\n        obj = _json_repair_minimal(m.group(1))\n        if obj is not None:\n            return obj\n\n    # 3) scan brace blocks non-greedy\n    for m in re.finditer(r\"\\{.*?\\}\", t, flags=re.S):\n        cand = m.group(0)\n        obj = _try_json_load(cand)\n        if obj is not None:\n            return obj\n        obj = _json_repair_minimal(cand)\n        if obj is not None:\n            return obj\n\n    return None\n\ndef _to_float(x):\n    if x is None:\n        return None\n    if isinstance(x, (int, float)):\n        return float(x)\n    s = str(x)\n    s = s.replace(\",\", \".\")\n    s = re.sub(r\"[^0-9\\.\\-]\", \"\", s)\n    try:\n        return float(s) if s else None\n    except Exception:\n        return None\n\ndef _to_str_or_none(x):\n    if x is None:\n        return None\n    s = str(x).strip()\n    return s if s else None\n\ndef _to_flags(x):\n    if x is None:\n        return []\n    if isinstance(x, list):\n        return [str(v) for v in x if str(v).strip()]\n    # split by comma/newline\n    s = str(x)\n    parts = re.split(r\"[,;\\n]+\", s)\n    return [p.strip() for p in parts if p.strip()]\n\ndef coerce_to_schema(task: str, obj: dict):\n    if not isinstance(obj, dict):\n        return None\n\n    if task == \"receipt_extract_text\":\n        out = {\n            \"vendor_name\": _to_str_or_none(obj.get(\"vendor_name\") or obj.get(\"vendor\") or obj.get(\"seller\")),\n            \"address\": _to_str_or_none(obj.get(\"address\") or obj.get(\"addr\")),\n            \"date\": _to_str_or_none(obj.get(\"date\")),\n            \"total_amount\": _to_float(obj.get(\"total_amount\") or obj.get(\"total\") or obj.get(\"amount\")),\n            \"currency\": _to_str_or_none(obj.get(\"currency\")) or \"VND\",\n            \"confidence\": _to_float(obj.get(\"confidence\")) if obj.get(\"confidence\") is not None else 0.5,\n            \"flags\": _to_flags(obj.get(\"flags\")),\n        }\n        return out\n\n    if task == \"invoice_extract_text\":\n        out = {\n            \"vendor_name\": _to_str_or_none(obj.get(\"vendor_name\") or obj.get(\"vendor\") or obj.get(\"seller\")),\n            \"invoice_no\": _to_str_or_none(obj.get(\"invoice_no\") or obj.get(\"invoice_number\") or obj.get(\"invoice\")),\n            \"date\": _to_str_or_none(obj.get(\"date\")),\n            \"subtotal\": _to_float(obj.get(\"subtotal\")),\n            \"tax\": _to_float(obj.get(\"tax\") or obj.get(\"vat\")),\n            \"total\": _to_float(obj.get(\"total\") or obj.get(\"total_amount\") or obj.get(\"amount\")),\n            \"currency\": _to_str_or_none(obj.get(\"currency\")) or \"VND\",\n            \"confidence\": _to_float(obj.get(\"confidence\")) if obj.get(\"confidence\") is not None else 0.5,\n            \"flags\": _to_flags(obj.get(\"flags\")),\n        }\n        return out\n\n    if task == \"journal_from_structured_txn\":\n        entries = obj.get(\"entries\")\n        if not isinstance(entries, list):\n            entries = []\n        norm_entries = []\n        for e in entries:\n            if not isinstance(e, dict):\n                continue\n            norm_entries.append({\n                \"account\": _to_str_or_none(e.get(\"account\")) or \"\",\n                \"debit\": _to_float(e.get(\"debit\")) or 0.0,\n                \"credit\": _to_float(e.get(\"credit\")) or 0.0,\n                \"memo\": _to_str_or_none(e.get(\"memo\")),\n            })\n        out = {\n            \"entries\": norm_entries,\n            \"confidence\": _to_float(obj.get(\"confidence\")) if obj.get(\"confidence\") is not None else 0.5,\n            \"flags\": _to_flags(obj.get(\"flags\")),\n        }\n        return out\n\n    return obj\n\n# ---- run distill again ----\ndef load_teacher_outputs(path):\n    out = {}\n    if not path:\n        return out\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            r = json.loads(line)\n            out[r[\"id\"]] = r\n    return out\n\nteacher_outputs = {k: load_teacher_outputs(v) for k, v in teacher_paths.items() if v}\n\ndef router_priority(task):\n    if task in [\"receipt_extract_text\", \"invoice_extract_text\"]:\n        return [\"open_finance_8b\", \"finance_llama3_8b\", \"fingpt_lora_llama3_8b\"]\n    if task == \"journal_from_structured_txn\":\n        return [\"finance_llama3_8b\", \"open_finance_8b\", \"fingpt_lora_llama3_8b\"]\n    return [\"finance_llama3_8b\", \"open_finance_8b\", \"fingpt_lora_llama3_8b\"]\n\ndistilled = []\ndropped = 0\npicked = {}\n\nwith open(kd_pool_path, \"r\", encoding=\"utf-8\") as f:\n    pool = [json.loads(x) for x in f]\n\nfor ex in pool:\n    task = ex[\"task\"]\n    cid = ex[\"id\"]\n\n    chosen_obj = None\n    chosen_teacher = None\n\n    for tname in router_priority(task):\n        if tname not in teacher_outputs:\n            continue\n        rec = teacher_outputs[tname].get(cid)\n        if not rec:\n            continue\n\n        raw = rec.get(\"raw\", \"\")\n        obj = extract_json_robust(raw)\n        obj = coerce_to_schema(task, obj) if obj is not None else None\n\n        if obj is not None and schema_pass(task, obj):\n            chosen_obj = obj\n            chosen_teacher = tname\n            break\n\n    if chosen_obj is None:\n        dropped += 1\n        continue\n\n    picked[chosen_teacher] = picked.get(chosen_teacher, 0) + 1\n    distilled.append({\n        \"id\": cid,\n        \"task\": task,\n        \"prompt\": build_prompt(task, ex[\"input\"]),\n        \"answer_json\": chosen_obj\n    })\n\nprint(\"KD distilled:\", len(distilled), \"| dropped:\", dropped)\nprint(\"picked_by_teacher:\", picked)\n\ndistill_path = str(DATA_DIR / \"distilled_train.jsonl\")\nwith open(distill_path, \"w\", encoding=\"utf-8\") as f:\n    for r in distilled:\n        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n\nprint(\"Saved:\", distill_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T16:13:05.084172Z","iopub.execute_input":"2026-01-21T16:13:05.084605Z","iopub.status.idle":"2026-01-21T16:13:05.913490Z","shell.execute_reply.started":"2026-01-21T16:13:05.084588Z","shell.execute_reply":"2026-01-21T16:13:05.913046Z"}},"outputs":[{"name":"stdout","text":"KD distilled: 354 | dropped: 96\npicked_by_teacher: {'finance_llama3_8b': 326, 'open_finance_8b': 28}\nSaved: /dev/shm/kaggle_ram/working/data/distilled_train.jsonl\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# CELL TRAIN (REPLACE) — bảo đảm lưu adapter vào 1 folder rõ ràng + tồn tại adapter_config.json\nfrom datasets import Dataset\nfrom peft import LoraConfig, get_peft_model\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nimport json, os\nfrom pathlib import Path\n\nassert QWEN32B_PATH is not None, \"Cannot find Qwen3-32B in /kaggle/input\"\n\n# Load Qwen base\nqwen_tok, qwen_base = load_4bit_model(QWEN32B_PATH)\n\ndef guess_lora_targets(model):\n    names = set()\n    for n, _ in model.named_modules():\n        if any(k in n for k in [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]):\n            names.add(n.split(\".\")[-1])\n    return sorted(list(names)) if names else [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"]\n\ntargets = guess_lora_targets(qwen_base)\nprint(\"LoRA targets:\", targets)\n\nlora_cfg = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=targets,\n)\n\nstudent = get_peft_model(qwen_base, lora_cfg)\nstudent.print_trainable_parameters()\n\n# Prepare dataset\nrows = []\nwith open(distill_path, \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        r = json.loads(line)\n        rows.append({\"text\": r[\"prompt\"] + \"\\n\\n\" + json.dumps(r[\"answer_json\"], ensure_ascii=False)})\n\nif len(rows) == 0:\n    raise RuntimeError(\"distilled_train.jsonl is empty\")\n\ntrain_ds = Dataset.from_list(rows)\n\nargs = TrainingArguments(\n    output_dir=str(WORKDIR / \"student_ckpt\"),\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=8,\n    learning_rate=2e-4,\n    num_train_epochs=1,\n    logging_steps=10,\n    save_steps=200,\n    bf16=True,\n    optim=\"paged_adamw_8bit\",\n    report_to=\"none\",\n)\n\ntrainer = SFTTrainer(\n    model=student,\n    args=args,\n    train_dataset=train_ds,\n    processing_class=qwen_tok,   # TRL mới dùng processing_class\n)\n\ntrainer.train()\n\n# ✅ SAVE ADAPTER to a concrete path (and export ADAPTER_DIR for later cells)\nADAPTER_DIR = Path(WORKDIR) / \"outputs\" / \"adapters\" / \"student_adapter\"\nADAPTER_DIR.mkdir(parents=True, exist_ok=True)\n\ntrainer.model.save_pretrained(str(ADAPTER_DIR))\nqwen_tok.save_pretrained(str(ADAPTER_DIR))\n\n# hard assert: must exist\nassert (ADAPTER_DIR / \"adapter_config.json\").exists(), f\"Missing adapter_config.json in {ADAPTER_DIR}\"\nprint(\"✅ Saved student adapter:\", str(ADAPTER_DIR))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T16:13:05.914127Z","iopub.execute_input":"2026-01-21T16:13:05.914276Z","iopub.status.idle":"2026-01-21T16:26:06.676953Z","shell.execute_reply.started":"2026-01-21T16:13:05.914261Z","shell.execute_reply":"2026-01-21T16:26:06.676481Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9e3921d618c43959c9bb5a1aed36348"}},"metadata":{}},{"name":"stdout","text":"LoRA targets: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\ntrainable params: 134,217,728 || all params: 32,896,340,992 || trainable%: 0.4080\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:2111: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Adding EOS to train dataset:   0%|          | 0/354 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ad45b2c15c4f7eb6c107a6e5b0333f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/354 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2c23a54b20e4315bbe45e79a39cfe6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/354 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae1777a018134043a26ab78775c78676"}},"metadata":{}},{"name":"stderr","text":"The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [45/45 02:23, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.011000</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.354100</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.299600</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.282800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"✅ Saved student adapter: /dev/shm/kaggle_ram/working/outputs/adapters/student_adapter\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# CELL EVAL (REPLACE) — per-task metrics, low-noise parsing, no x3 repeats by default\nimport json, re, random, math\nfrom collections import defaultdict\nfrom datetime import datetime\n\n# ---------- Robust JSON parsing (same spirit as your KD distill) ----------\ndef _strip_code_fences(s: str) -> str:\n    if not s:\n        return s\n    s = s.strip()\n    s = re.sub(r\"^```(?:json)?\\s*\", \"\", s, flags=re.I)\n    s = re.sub(r\"\\s*```$\", \"\", s)\n    return s.strip()\n\ndef _try_json_load(s: str):\n    try:\n        return json.loads(s)\n    except Exception:\n        return None\n\ndef _json_repair_minimal(s: str):\n    if s is None:\n        return None\n    s = _strip_code_fences(s).strip()\n    s = re.sub(r\",\\s*}\", \"}\", s)\n    s = re.sub(r\",\\s*]\", \"]\", s)\n    if \"'\" in s and '\"' not in s:\n        s = s.replace(\"'\", '\"')\n    return _try_json_load(s)\n\ndef extract_json_robust(text: str):\n    if text is None:\n        return None\n    t = _strip_code_fences(text)\n\n    # whole\n    obj = _try_json_load(t)\n    if obj is not None:\n        return obj\n\n    # ```json {...} ```\n    m = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", text, flags=re.S | re.I)\n    if m:\n        obj = _try_json_load(m.group(1)) or _json_repair_minimal(m.group(1))\n        if obj is not None:\n            return obj\n\n    # scan all {...} non-greedy\n    for m in re.finditer(r\"\\{.*?\\}\", t, flags=re.S):\n        cand = m.group(0)\n        obj = _try_json_load(cand) or _json_repair_minimal(cand)\n        if obj is not None:\n            return obj\n\n    return None\n\ndef _to_float(x):\n    if x is None:\n        return None\n    if isinstance(x, (int, float)):\n        return float(x)\n    s = str(x).replace(\",\", \".\")\n    s = re.sub(r\"[^0-9\\.\\-]\", \"\", s)\n    try:\n        return float(s) if s else None\n    except Exception:\n        return None\n\ndef _to_str_or_none(x):\n    if x is None:\n        return None\n    s = str(x).strip()\n    return s if s else None\n\ndef _to_flags(x):\n    if x is None:\n        return []\n    if isinstance(x, list):\n        return [str(v) for v in x if str(v).strip()]\n    parts = re.split(r\"[,;\\n]+\", str(x))\n    return [p.strip() for p in parts if p.strip()]\n\ndef coerce_to_schema(task: str, obj: dict):\n    if not isinstance(obj, dict):\n        return None\n\n    if task == \"receipt_extract_text\":\n        return {\n            \"vendor_name\": _to_str_or_none(obj.get(\"vendor_name\") or obj.get(\"vendor\") or obj.get(\"seller\")),\n            \"address\": _to_str_or_none(obj.get(\"address\") or obj.get(\"addr\")),\n            \"date\": _to_str_or_none(obj.get(\"date\")),\n            \"total_amount\": _to_float(obj.get(\"total_amount\") or obj.get(\"total\") or obj.get(\"amount\")),\n            \"currency\": _to_str_or_none(obj.get(\"currency\")) or \"VND\",\n            \"confidence\": _to_float(obj.get(\"confidence\")) if obj.get(\"confidence\") is not None else 0.5,\n            \"flags\": _to_flags(obj.get(\"flags\")),\n        }\n\n    if task == \"invoice_extract_text\":\n        return {\n            \"vendor_name\": _to_str_or_none(obj.get(\"vendor_name\") or obj.get(\"vendor\") or obj.get(\"seller\")),\n            \"invoice_no\": _to_str_or_none(obj.get(\"invoice_no\") or obj.get(\"invoice_number\") or obj.get(\"invoice\")),\n            \"date\": _to_str_or_none(obj.get(\"date\")),\n            \"subtotal\": _to_float(obj.get(\"subtotal\")),\n            \"tax\": _to_float(obj.get(\"tax\") or obj.get(\"vat\")),\n            \"total\": _to_float(obj.get(\"total\") or obj.get(\"total_amount\") or obj.get(\"amount\")),\n            \"currency\": _to_str_or_none(obj.get(\"currency\")) or \"VND\",\n            \"confidence\": _to_float(obj.get(\"confidence\")) if obj.get(\"confidence\") is not None else 0.5,\n            \"flags\": _to_flags(obj.get(\"flags\")),\n        }\n\n    if task == \"journal_from_structured_txn\":\n        entries = obj.get(\"entries\")\n        if not isinstance(entries, list):\n            entries = []\n        norm_entries = []\n        for e in entries:\n            if not isinstance(e, dict):\n                continue\n            norm_entries.append({\n                \"account\": _to_str_or_none(e.get(\"account\")) or \"\",\n                \"debit\": _to_float(e.get(\"debit\")) or 0.0,\n                \"credit\": _to_float(e.get(\"credit\")) or 0.0,\n                \"memo\": _to_str_or_none(e.get(\"memo\")),\n            })\n        return {\n            \"entries\": norm_entries,\n            \"confidence\": _to_float(obj.get(\"confidence\")) if obj.get(\"confidence\") is not None else 0.5,\n            \"flags\": _to_flags(obj.get(\"flags\")),\n        }\n\n    return obj\n\n# ---------- Quick exact-field checks (only when gold exists) ----------\ndef field_exact(gold, pred, key):\n    if gold is None or pred is None:\n        return None\n    if gold.get(key) is None:\n        return None\n    return 1.0 if str(gold.get(key)).strip() == str(pred.get(key)).strip() else 0.0\n\n# ---------- Main eval ----------\n@torch.no_grad()\ndef eval_model_v2(tok, mdl, cases, batch_size=32, max_new_tokens=256, determinism_k=40, determinism_repeats=2):\n    \"\"\"\n    - Default: single-pass inference (no repeats) => much faster.\n    - Determinism: only check on a small random subset determinism_k with repeats=2.\n    - Metrics returned per task + overall.\n    \"\"\"\n    # group by task for per-task metrics\n    by_task = defaultdict(list)\n    for ex in cases:\n        by_task[ex[\"task\"]].append(ex)\n\n    def run_once(examples):\n        n = len(examples)\n        json_valid = 0\n        schema_ok = 0\n\n        # field metrics only where gold is present (mostly receipts)\n        vendor_acc = []\n        date_acc = []\n        total_acc = []\n\n        # keep failures for debugging (small sample)\n        bad_samples = []\n\n        for i in range(0, n, batch_size):\n            batch = examples[i:i+batch_size]\n            prompts = [build_prompt(ex[\"task\"], ex[\"input\"]) for ex in batch]\n            texts = generate_batch(tok, mdl, prompts, max_new_tokens=max_new_tokens)\n\n            for ex, t in zip(batch, texts):\n                task = ex[\"task\"]\n                gold = ex.get(\"gold\")\n\n                obj = extract_json_robust(t)\n                obj = coerce_to_schema(task, obj) if obj is not None else None\n\n                if obj is not None:\n                    json_valid += 1\n                    if schema_pass(task, obj):\n                        schema_ok += 1\n                    else:\n                        if len(bad_samples) < 10:\n                            bad_samples.append({\"id\": ex[\"id\"], \"task\": task, \"reason\": \"schema_fail\", \"raw\": t[:500]})\n                else:\n                    if len(bad_samples) < 10:\n                        bad_samples.append({\"id\": ex[\"id\"], \"task\": task, \"reason\": \"json_parse_fail\", \"raw\": t[:500]})\n\n                if gold and isinstance(gold, dict) and task in [\"receipt_extract_text\",\"invoice_extract_text\"]:\n                    v = field_exact(gold, obj, \"vendor_name\")\n                    d = field_exact(gold, obj, \"date\")\n                    if task == \"receipt_extract_text\":\n                        ta = field_exact(gold, obj, \"total_amount\")\n                    else:\n                        ta = field_exact(gold, obj, \"total\")\n                    if v is not None: vendor_acc.append(v)\n                    if d is not None: date_acc.append(d)\n                    if ta is not None: total_acc.append(ta)\n\n        def avg(xs):\n            return float(sum(xs)/len(xs)) if xs else None\n\n        return {\n            \"n\": n,\n            \"json_valid_rate\": json_valid / max(1, n),\n            \"schema_pass_rate\": schema_ok / max(1, n),\n            \"vendor_acc\": avg(vendor_acc),\n            \"date_acc\": avg(date_acc),\n            \"total_acc\": avg(total_acc),\n            \"debug_bad_samples\": bad_samples,\n        }\n\n    # per-task\n    per_task = {task: run_once(exs) for task, exs in by_task.items()}\n\n    # overall\n    overall = run_once(cases)\n\n    # determinism on subset only\n    det_rate = None\n    if determinism_k and determinism_repeats >= 2:\n        sub = random.sample(cases, k=min(determinism_k, len(cases)))\n        same = 0\n        for i in range(0, len(sub), batch_size):\n            batch = sub[i:i+batch_size]\n            prompts = [build_prompt(ex[\"task\"], ex[\"input\"]) for ex in batch]\n\n            outs = []\n            for _ in range(determinism_repeats):\n                texts = generate_batch(tok, mdl, prompts, max_new_tokens=max_new_tokens)\n                objs = []\n                for ex, t in zip(batch, texts):\n                    obj = extract_json_robust(t)\n                    obj = coerce_to_schema(ex[\"task\"], obj) if obj is not None else None\n                    objs.append(json.dumps(obj, ensure_ascii=False, sort_keys=True) if obj is not None else None)\n                outs.append(objs)\n\n            for j in range(len(batch)):\n                vals = [outs[r][j] for r in range(determinism_repeats)]\n                if len(set(vals)) == 1:\n                    same += 1\n\n        det_rate = same / max(1, len(sub))\n\n    return {\n        \"overall\": {**overall, \"determinism_rate_subset\": det_rate, \"determinism_subset_n\": min(determinism_k, len(cases))},\n        \"per_task\": {k: {**v} for k, v in per_task.items()},\n    }\n\n# ---------- Run evaluation BASE + STUDENT ----------\nwith open(eval_path, \"r\", encoding=\"utf-8\") as f:\n    eval_cases = [json.loads(x) for x in f]\n\n# BASE\nbase_tok, base_mdl = load_4bit_model(QWEN32B_PATH)\nbase_report = eval_model_v2(\n    base_tok, base_mdl, eval_cases,\n    batch_size=32,\n    max_new_tokens=256,       # giảm nhiễu/thời gian (JSON task thường không cần 320)\n    determinism_k=40,         # chỉ check subset\n    determinism_repeats=2\n)\nprint(\"BASE overall:\", {k: v for k, v in base_report[\"overall\"].items() if k != \"debug_bad_samples\"})\nprint(\"BASE per_task schema_pass:\", {k: v[\"schema_pass_rate\"] for k, v in base_report[\"per_task\"].items()})\n\n# STUDENT (adapter)\nfrom peft import PeftModel\nstudent_tok, student_base = load_4bit_model(QWEN32B_PATH)\nstudent_mdl = PeftModel.from_pretrained(student_base, ADAPTER_DIR)\nstudent_mdl.eval()\n\nstudent_report = eval_model_v2(\n    student_tok, student_mdl, eval_cases,\n    batch_size=32,\n    max_new_tokens=256,\n    determinism_k=40,\n    determinism_repeats=2\n)\nprint(\"STUDENT overall:\", {k: v for k, v in student_report[\"overall\"].items() if k != \"debug_bad_samples\"})\nprint(\"STUDENT per_task schema_pass:\", {k: v[\"schema_pass_rate\"] for k, v in student_report[\"per_task\"].items()})\n\nreport = {\n    \"base\": base_report,\n    \"student\": student_report,\n    \"meta\": {\n        \"eval_path\": str(eval_path),\n        \"max_new_tokens\": 256,\n        \"batch_size\": 32,\n        \"determinism_k\": 40,\n        \"determinism_repeats\": 2,\n    }\n}\n\nreport_path = str(DATA_DIR / \"eval_report_v2.json\")\nwith open(report_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(report, f, ensure_ascii=False, indent=2)\n\nprint(\"Saved report:\", report_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T16:30:22.993177Z","iopub.execute_input":"2026-01-21T16:30:22.993791Z","iopub.status.idle":"2026-01-21T17:01:30.275152Z","shell.execute_reply.started":"2026-01-21T16:30:22.993760Z","shell.execute_reply":"2026-01-21T17:01:30.274693Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2c5451c49f04a1ca6ca89e2c9bc02bf"}},"metadata":{}},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"BASE overall: {'n': 450, 'json_valid_rate': 0.41555555555555557, 'schema_pass_rate': 0.19111111111111112, 'vendor_acc': None, 'date_acc': None, 'total_acc': None, 'determinism_rate_subset': 1.0, 'determinism_subset_n': 40}\nBASE per_task schema_pass: {'receipt_extract_text': 0.12333333333333334, 'journal_from_structured_txn': 0.3333333333333333}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c422a1f2c89f442fbbd7c0850d8408ac"}},"metadata":{}},{"name":"stdout","text":"STUDENT overall: {'n': 450, 'json_valid_rate': 1.0, 'schema_pass_rate': 1.0, 'vendor_acc': None, 'date_acc': None, 'total_acc': None, 'determinism_rate_subset': 1.0, 'determinism_subset_n': 40}\nSTUDENT per_task schema_pass: {'receipt_extract_text': 1.0, 'journal_from_structured_txn': 1.0}\nSaved report: /dev/shm/kaggle_ram/working/data/eval_report_v2.json\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# FINAL SAVE (adapter) — student adapter in RAM\nADAPTER_DIR = str(WORKDIR / \"student_adapter\")\ntrainer.model.save_pretrained(ADAPTER_DIR)\nqwen_tok.save_pretrained(ADAPTER_DIR)\nprint(\"Saved student adapter dir:\", ADAPTER_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T17:01:30.276015Z","iopub.execute_input":"2026-01-21T17:01:30.276161Z","iopub.status.idle":"2026-01-21T17:01:30.658431Z","shell.execute_reply.started":"2026-01-21T17:01:30.276146Z","shell.execute_reply":"2026-01-21T17:01:30.657948Z"}},"outputs":[{"name":"stdout","text":"Saved student adapter dir: /dev/shm/kaggle_ram/working/student_adapter\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# CELL SAVE (ADD NEW, cuối notebook) — xuất student adapter + tokenizer + lineage để tải về\nimport json, shutil\nfrom pathlib import Path\n\nOUT_DIR = WORKDIR / \"outputs\"\nREL = Path(\"/kaggle/working\") / \"release\" / \"qwen3-32b-accounting-distilled-v0.1.0\"\nREL.mkdir(parents=True, exist_ok=True)\n\nADAPTER_OUT = REL / \"adapters\"\nTOKEN_OUT  = REL / \"tokenizer\"\nADAPTER_OUT.mkdir(parents=True, exist_ok=True)\nTOKEN_OUT.mkdir(parents=True, exist_ok=True)\n\n# Save LoRA adapter (nhẹ) + tokenizer\ntrainer.model.save_pretrained(str(ADAPTER_OUT))\nqwen_tok.save_pretrained(str(TOKEN_OUT))\n\nlineage = {\n    \"model_name\": \"qwen3-32b-accounting-distilled\",\n    \"version\": \"v0.1.0\",\n    \"method\": \"Knowledge Distillation (multi-teacher) + QLoRA SFT\",\n    \"teachers\": TEACHERS,\n    \"paths\": {\n        \"distill_path\": str(distill_path),\n        \"adapter_dir\": str(ADAPTER_OUT),\n        \"tokenizer_dir\": str(TOKEN_OUT),\n    },\n}\nwith open(REL / \"lineage.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(lineage, f, ensure_ascii=False, indent=2)\n\n# Zip để download dễ\nzip_path = shutil.make_archive(str(REL), \"zip\", root_dir=str(REL))\nprint(\"✅ RELEASE folder:\", REL)\nprint(\"✅ ZIP:\", zip_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T17:01:30.659061Z","iopub.execute_input":"2026-01-21T17:01:30.659212Z","iopub.status.idle":"2026-01-21T17:01:54.653479Z","shell.execute_reply.started":"2026-01-21T17:01:30.659190Z","shell.execute_reply":"2026-01-21T17:01:54.653035Z"}},"outputs":[{"name":"stdout","text":"✅ RELEASE folder: /kaggle/working/release/qwen3-32b-accounting-distilled-v0.1.0\n✅ ZIP: /kaggle/working/release/qwen3-32b-accounting-distilled-v0.1.0.zip\n","output_type":"stream"}],"execution_count":14}]}